{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from textblob import TextBlob\n",
    "import collections\n",
    "import statistics\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.preprocessing import normalize\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>period_count</th>\n",
       "      <th>word_length</th>\n",
       "      <th>char_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   qid  \\\n",
       "0           0  00002165364db923c7e6   \n",
       "1           1  000032939017120e6e44   \n",
       "2           2  0000412ca6e4628ce2cf   \n",
       "3           3  000042bf85aa498cd78e   \n",
       "4           4  0000455dfa3e01eae3af   \n",
       "\n",
       "                                       question_text  target  period_count  \\\n",
       "0  How did Quebec nationalists see their province...       0             0   \n",
       "1  Do you have an adopted dog, how would you enco...       0             0   \n",
       "2  Why does velocity affect time? Does velocity a...       0             0   \n",
       "3  How did Otto von Guericke used the Magdeburg h...       0             0   \n",
       "4  Can I convert montra helicon D to a mountain b...       0             0   \n",
       "\n",
       "   word_length  char_length  polarity  subjectivity  \n",
       "0           13           72       0.0           0.0  \n",
       "1           16           81       0.0           0.0  \n",
       "2           10           67       0.0           0.0  \n",
       "3            9           57       0.0           0.0  \n",
       "4           15           77       0.0           0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('new_set.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_score(train1):\n",
    "  train1.loc[:,'word'] = train1['question_text'].apply(lambda x: [re.sub('[^A-Za-z0-9]+', '', i) for i in x.split(\" \")])\n",
    "  bad_word_dict=collections.Counter([y for x in train1['word'][train1['target']==1] for y in x])\n",
    "  good_word_dict=collections.Counter([y for x in train1['word'][train1['target']==0] for y in x])\n",
    "  total_word_dict=collections.Counter([y for x in train1['word'] for y in x])\n",
    "  for i in total_word_dict:\n",
    "      if i not in bad_word_dict:\n",
    "          bad_word_dict[i] = -1\n",
    "      if i not in good_word_dict:    \n",
    "          good_word_dict[i] = 2\n",
    "  raw_word_score = {i: (bad_word_dict[i]*good_word_dict[i])/\n",
    "                    (total_word_dict[i]) for i in total_word_dict}\n",
    "  raw_word_score_2 = {i: (bad_word_dict[i]-good_word_dict[i])/\n",
    "                    (total_word_dict[i]) for i in total_word_dict}\n",
    "  mean_score = statistics.mean(list(raw_word_score.values()))\n",
    "  stdev = statistics.stdev(list(raw_word_score.values()))\n",
    "\n",
    "  mean_score_2 = statistics.mean(list(raw_word_score_2.values()))\n",
    "  stdev_2 = statistics.stdev(list(raw_word_score_2.values()))\n",
    "  standard_word_score = {i : (raw_word_score[i]-mean_score)/stdev for i in raw_word_score}\n",
    "  standard_word_score_2 = {i : (raw_word_score_2[i]-mean_score_2)/stdev_2 for i in raw_word_score_2}\n",
    "  train1.loc[:,'score_1'] = train1['word'].apply(lambda x: sum([raw_word_score[i] for i in x]))\n",
    "  train1.loc[:,'score_2'] = train1['word'].apply(lambda x: sum([raw_word_score_2[i] for i in x]))\n",
    "  return train1.drop(columns = [\"question_text\",\"word\",\"target\"]),raw_word_score,raw_word_score_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['question_text','target','period_count','char_length','polarity'] \n",
    "X=train[cols]\n",
    "y=train['target']\n",
    "\n",
    "X_train,y_train = X,y\n",
    "\n",
    "\n",
    "X_train,score1,score2 = train_score(X_train)\n",
    "X_train = ((X_train-X_train.min())/(X_train.max()-X_train.min()))\n",
    "\n",
    "X_train,  y_train  = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royluo/anaconda3/envs/devfest/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/royluo/anaconda3/envs/devfest/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "ranforest = RandomForestClassifier()\n",
    "adaboo = AdaBoostClassifier()\n",
    "GBC = GradientBoostingClassifier()\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "ranforest.fit(X_train, y_train)\n",
    "adaboo.fit(X_train, y_train)\n",
    "GBC.fit(X_train, y_train)\n",
    "\n",
    "logreg_feature = logreg.predict(X_train)\n",
    "ranforest_feature = ranforest.predict(X_train)\n",
    "adaboo_feature = adaboo.predict(X_train)\n",
    "GBC_feature = GBC.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1306122/1306122 [==============================] - 86s 66us/step - loss: 0.1726 - acc: 0.9444\n",
      "Epoch 2/2\n",
      "1306122/1306122 [==============================] - 84s 64us/step - loss: 0.1564 - acc: 0.9468\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "rate = .1\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(20, activation = tf.nn.relu))\n",
    "#model.add(tf.keras.layers.Dense(32, activation = tf.nn.relu))\n",
    "#model.add(tf.keras.layers.Dense(32, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(6, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(6, activation = tf.nn.relu))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(2, activation = tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(X_train,y_train,epochs = 2)\n",
    "tf_feature = model.predict_classes([X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(objective= 'binary:logistic')\n",
    "\n",
    "features_train = np.concatenate(([logreg_feature],[ranforest_feature],[adaboo_feature],\n",
    "                           [GBC_feature],[tf_feature])).transpose()\n",
    "gbm.fit(features_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now testing the final model with two real sentences. [1] means toxicity and insincerity, [0] means ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text\n",
      "This tax increase is ridiculous, the republicans are despicable and should go to jail for this crime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royluo/anaconda3/envs/devfest/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Enter your text\n",
      "Fuck the weather. I hate having to wear like a fat pig every time i go outside\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/royluo/anaconda3/envs/devfest/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    question1 = input('Enter your text\\n')\n",
    "    #question1 = 'Has the U.S become the largest dictatorship in this world?'\n",
    "    avg_1 = statistics.mean(list(score1.values()))\n",
    "    avg_2 = statistics.mean(list(score2.values()))\n",
    "\n",
    "    word_length = len(question1.split(' '))\n",
    "    char_length = len(question1)\n",
    "    period_count = question1.count('.')\n",
    "    word = [re.sub('[^A-Za-z0-9]+', '', i) for i in question1.split(\" \")]\n",
    "    score_1 = sum([score1[i] if i in score1 else avg_1 for i in word ])\n",
    "    score_2 = sum([score2[i] if i in score2 else avg_2 for i in word ])\n",
    "    sent = TextBlob(question1).sentiment\n",
    "\n",
    "    raw_input = [period_count,char_length,sent.polarity,score_1,score_2]\n",
    "    new_set = train_score(X)[0]\n",
    "\n",
    "    logreg_input = logreg.predict([question_input])\n",
    "    ranforest_input = ranforest.predict([question_input])\n",
    "    adaboo_input = adaboo.predict([question_input])\n",
    "    GBC_input = GBC.predict([question_input])\n",
    "    tf_input = model.predict_classes(np.array([question_input]))\n",
    "\n",
    "    features = ['period_count','char_length','polarity','score_1','score_2']\n",
    "\n",
    "    for i,feature in enumerate(features):\n",
    "        M = new_set[feature].max()\n",
    "        m = new_set[feature].min()\n",
    "        raw_input[i] = (raw_input[i] - m) / (M-m)\n",
    "    question_input = np.array(raw_input)\n",
    "    print(gbm.predict(np.array([logreg_input,ranforest_input,adaboo_input,GBC_input,tf_input]).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
